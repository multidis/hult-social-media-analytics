{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b59ef8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect relevant content through the Reddit API.\n",
    "import json\n",
    "import praw\n",
    "# PRAW documentation:\n",
    "#  https://praw.readthedocs.io/en/stable/code_overview/reddit_instance.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50c06462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: enter proper access credential in the config-file;\n",
    "# follow instructions in reddit_credentials_verify.ipynb\n",
    "import config_reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ded247a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# establish an API connection and verify read-only access\n",
    "reddit = praw.Reddit(user_agent=f\"Exploration script by /u/{config_reddit.user_name}\",\n",
    "                     client_id=config_reddit.app_id,\n",
    "                     client_secret=config_reddit.app_secret)\n",
    "reddit.read_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e6db275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a subreddit of interest\n",
    "# MODIFY this to what you prefer to analyze\n",
    "#\n",
    "# Example (take the string from the ending-part of the subreddit URL):\n",
    "#  https://www.reddit.com/r/ebikes/\n",
    "query_subreddit = 'ebikes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7360dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide how many top-\"hot\" posts to query\n",
    "nposts = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f6b88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect ids of the top posts within the chosen subreddit\n",
    "post_ids = []\n",
    "subreddit = reddit.subreddit(query_subreddit)\n",
    "for p in subreddit.hot(limit = nposts):\n",
    "    post_ids.append(p.id)\n",
    "# check how many posts (submissions) were collected\n",
    "len(post_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7310299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bike friendly neighborhoods start at the local level. You can make a difference.\n",
      "1. Transportation infrastructure policy is largely done at the local level. \n",
      "2. A shockingly small number of people are actually involved in making this policy. \n",
      "3. Individual Advocates can have a huge impact at the city level. \n",
      "\n",
      "Bottom line: Anyone can make a difference! \n",
      "\n",
      "Even if you can't afford to catch a local politicians ear via donation... or if you don't have the free time to show up at a city hall meeting... you can still be an educator/advocate on social media. \n",
      "\n",
      "**Education**\n",
      "\n",
      "Youtube:\n",
      "\n",
      "* [Why City Design is Important \\(and Why I Hate Houston\\) by Not Just Bikes](https://www.youtube.com/watch?v=uxykI30fS54)\n",
      "\n",
      "* [The Ugly, Dangerous, and Inefficient Stroads found all over the US & Canada by Not Just Bikes](https://www.youtube.com/watch?v=ORzNZUeUHAM)\n",
      "\n",
      "* [Bike lanes are not enough by City Beautiful](https://www.youtube.com/watch?v=p36skNda3KE)\n",
      "\n",
      "\n",
      "\n",
      "Tiktok:\n",
      "\n",
      "* [Phil Sustainability & Enviro](https://www.tiktok.com/@philritz?lang=en)\n",
      "\n",
      "* [TalkingCities](https://www.tiktok.com/@talkingcities)\n",
      "\n",
      "Web:\n",
      "\n",
      "* [Strong Towns](https://www.strongtowns.org/bike)\n",
      "\n",
      "**Get involved:**\n",
      "\n",
      "* [Strong Towns on Facebook](https://www.facebook.com/strongtowns) \n",
      "\n",
      "* [People for Bikes on Facebook](https://www.facebook.com/PeopleForBikes)\n",
      "\n",
      "\n",
      "*Please leave a comment if you have any other resources you'd like to add.*\n"
     ]
    }
   ],
   "source": [
    "# example post details\n",
    "post_details = reddit.submission(id = post_ids[1])\n",
    "print(post_details.title)\n",
    "print(post_details.selftext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e50991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide how many top comments to query per post;\n",
    "# NOTE: larger number of comments may dilute the content (irrelevant text)\n",
    "ncomments = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d324eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to collect post data\n",
    "def collect_post_data(post_id, ncomments, reddit):\n",
    "    psubm = reddit.submission(id = post_id)\n",
    "    pdata = {'id': post_id, 'title': psubm.title, 'text': psubm.selftext}\n",
    "    \n",
    "    # collect first- and second-level comments\n",
    "    pcomm = []\n",
    "    psubcomm = []\n",
    "    psubm.comments.replace_more(limit = ncomments)\n",
    "    for top_comment in psubm.comments:\n",
    "        pcomm.append(top_comment.body)\n",
    "        for lev2_comment in top_comment.replies:\n",
    "            psubcomm.append(lev2_comment.body)\n",
    "    \n",
    "    # assemble the data together\n",
    "    pdata['comments_lev1'] = pcomm\n",
    "    pdata['comments_lev2'] = psubcomm\n",
    "    \n",
    "    return pdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34039012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect information for each post\n",
    "posts_all = [collect_post_data(pid, ncomments, reddit) for pid in post_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "806ebea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save collected data to json file\n",
    "file_out = f\"raw_post_comment_data.json\"\n",
    "with open(file_out, mode='w') as f:\n",
    "    f.write(json.dumps(posts_all, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
